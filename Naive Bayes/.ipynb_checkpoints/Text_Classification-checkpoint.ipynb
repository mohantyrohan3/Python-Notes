{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2125169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f268fbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups=fetch_20newsgroups() \n",
    "\n",
    "stops=set(stopwords.words('english'))\n",
    "\n",
    "punctuations=list(string.punctuation)\n",
    "\n",
    "stops.update(punctuations)\n",
    "\n",
    "newsgroups.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b5c7062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mohan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51735193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_stops=np.loadtxt(\"datasets/stopwords.txt\", dtype=str, delimiter=\" \")\n",
    "stops.update(more_stops)\n",
    "len(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d57d798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e1dc4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents=newsgroups.data\n",
    "\n",
    "all_categories=newsgroups.target\n",
    "\n",
    "all_documents_modified=[word_tokenize(doc) for doc in all_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb82df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mohan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baad6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test=train_test_split(all_documents_modified, all_categories, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb2b239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=[]\n",
    "\n",
    "for doc in x_train:\n",
    "    for word in doc:\n",
    "        if (word.lower() not in stops) and len(word)!=1 and len(word)!=2 and word[0]!=\"'\" and word!=\"n't\" and word[0]!=\".\":\n",
    "            all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b7c2f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1179675"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "730dd8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_dict(all_words):\n",
    "    dic=dict()\n",
    "    for word in all_words:\n",
    "        if word in dic.keys():\n",
    "            dic[word]+=1\n",
    "        else:\n",
    "            dic[word]=1\n",
    "    return dic\n",
    "\n",
    "dic=freq_dict(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92b2e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "freq=np.array([i for i in dic.values()])\n",
    "words=np.array([i for i in dic.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93e9118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=words[np.argsort(freq)][::-1]\n",
    "freq=np.sort(freq)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c37af2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 47)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=words[20:4000]\n",
    "#features variable contains all the top words which are most frequently used in all our documents. \n",
    "freq[20], freq[3999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74fe218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_modifier(x_data, features):\n",
    "    modified_data=np.zeros((len(x_data), len(features)))\n",
    "    \n",
    "    for i in range(len(x_data)):\n",
    "        \n",
    "        current_doc=x_data[i]\n",
    "        \n",
    "        for word in current_doc:\n",
    "           \n",
    "            if word in features:\n",
    "               \n",
    "                for j in range(len(features)):\n",
    "                    \n",
    "                    if features[j]==word:\n",
    "                        modified_data[i][j]+=1\n",
    "    \n",
    "    return modified_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "750ca4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_modified = data_modifier(x_train, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d9809ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_modified= data_modifier(x_test, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb78d16",
   "metadata": {},
   "source": [
    "## Trying out the inbuilt Multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5f90e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8193708024036762"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=MultinomialNB()\n",
    "clf.fit(x_train_modified, y_train)\n",
    "clf.score(x_test_modified, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd224d",
   "metadata": {},
   "source": [
    "## Writing our own Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cccb4b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    count=dict()\n",
    "    for i in range(20):\n",
    "        needed_docs=x_train[y_train==i]\n",
    "    \n",
    "        count[i]=dict()\n",
    "        \n",
    "        count[i]['total']=0\n",
    "        \n",
    "        for j in range(len(features)):\n",
    "            count[i][features[j]]=needed_docs[:, j].sum()\n",
    "            \n",
    "            count[i]['total']+=count[i][features[j]]\n",
    "    return count\n",
    "\n",
    "\n",
    "def probability(dictionary, x, current_class):\n",
    "    probas_for_each_word=[]\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        \n",
    "        if x[i]!=0:\n",
    "            \n",
    "            numerator=dictionary[current_class][features[i]]\n",
    "            \n",
    "            denominator=dictionary[current_class]['total']\n",
    "            \n",
    "            proba=np.log((numerator+1)/(denominator+len(x)))\n",
    "            \n",
    "            probas_for_each_word.append(proba)\n",
    "            \n",
    "    return sum(probas_for_each_word)\n",
    "\n",
    "\n",
    "def predict_single(dic, x):\n",
    "    classes = dictionary.keys()\n",
    "    \n",
    "    best_p = -1000\n",
    "    best_class = -1\n",
    "    \n",
    "    first_run = True\n",
    "   \n",
    "    for current_class in classes:\n",
    "        \n",
    "        p_current_class = probability(dic, x, current_class)\n",
    "        if (first_run or p_current_class > best_p):\n",
    "            \n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "            \n",
    "        first_run = False\n",
    "    \n",
    "    return best_class\n",
    "\n",
    "\n",
    "def predict(x_test, dic):\n",
    "    y_pred=[]\n",
    "    \n",
    "    for doc in x_test:\n",
    "        \n",
    "        y_pred.append(predict_single(dic, doc))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccee2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=fit(x_train_modified, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "674654bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=predict(x_test_modified, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04f615ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91    0    0    0    0    0    0    0    0    0    0    0    0    1    0    8    1    0    1    12    \n",
      "0    118    4    11    5    7    2    0    0    0    0    1    1    1    0    1    0    0    0    1    \n",
      "0    11    99    17    2    9    0    1    0    0    0    0    0    0    0    0    0    0    0    0    \n",
      "0    9    3    122    7    2    4    2    0    0    0    1    1    0    0    1    0    0    0    0    \n",
      "1    4    0    16    108    0    5    2    1    0    0    0    0    1    0    0    0    0    0    0    \n",
      "0    25    2    6    3    113    0    1    2    0    0    0    1    0    0    0    0    0    0    0    \n",
      "0    7    0    8    0    1    112    5    2    3    1    1    4    1    0    1    0    0    1    0    \n",
      "0    2    0    2    0    0    6    115    6    1    0    0    4    1    0    0    0    0    0    0    \n",
      "0    1    0    0    0    0    4    11    111    0    0    0    1    0    0    0    3    0    0    0    \n",
      "0    1    0    2    0    0    0    0    0    127    1    0    1    0    0    1    0    0    0    2    \n",
      "0    0    0    0    1    0    2    2    1    9    119    0    0    0    0    0    0    0    0    2    \n",
      "0    2    0    0    0    1    0    0    1    0    0    138    0    0    0    0    2    0    0    1    \n",
      "0    13    1    21    10    1    4    5    0    1    0    1    97    1    0    0    0    0    1    1    \n",
      "0    4    0    1    1    0    2    1    0    0    0    0    2    138    1    0    1    0    0    0    \n",
      "0    9    1    1    1    0    2    2    0    1    0    1    0    2    129    1    1    0    4    0    \n",
      "1    2    0    0    0    0    2    0    1    0    0    0    1    1    0    145    2    0    1    3    \n",
      "1    2    0    0    0    0    1    1    1    2    0    2    0    1    0    0    124    0    2    3    \n",
      "3    7    0    2    0    0    2    0    0    0    0    0    0    0    0    1    1    127    6    0    \n",
      "1    3    0    0    0    0    2    1    0    3    0    3    0    0    0    0    11    3    105    6    \n",
      "8    1    0    0    0    0    0    0    0    0    0    0    0    0    2    12    8    1    3    66    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#printing the confusion matrix for our own naive bayes classifier.\n",
    "#here i am manually printing the confusion matrix for a more clear view.\n",
    "for i in confusion_matrix(y_true=y_test, y_pred=y_predicted):\n",
    "    for j in i:\n",
    "        print(j, end=\"    \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69f35861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83       114\n",
      "           1       0.53      0.78      0.63       152\n",
      "           2       0.90      0.71      0.80       139\n",
      "           3       0.58      0.80      0.68       152\n",
      "           4       0.78      0.78      0.78       138\n",
      "           5       0.84      0.74      0.79       153\n",
      "           6       0.75      0.76      0.75       147\n",
      "           7       0.77      0.84      0.80       137\n",
      "           8       0.88      0.85      0.86       131\n",
      "           9       0.86      0.94      0.90       135\n",
      "          10       0.98      0.88      0.93       136\n",
      "          11       0.93      0.95      0.94       145\n",
      "          12       0.86      0.62      0.72       157\n",
      "          13       0.93      0.91      0.92       151\n",
      "          14       0.98      0.83      0.90       155\n",
      "          15       0.85      0.91      0.88       159\n",
      "          16       0.81      0.89      0.84       140\n",
      "          17       0.97      0.85      0.91       149\n",
      "          18       0.85      0.76      0.80       138\n",
      "          19       0.68      0.65      0.67       101\n",
      "\n",
      "    accuracy                           0.81      2829\n",
      "   macro avg       0.83      0.81      0.82      2829\n",
      "weighted avg       0.83      0.81      0.82      2829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true=y_test, y_pred=y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0efc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
